#!/usr/bin/env python3
"""
Deep cleanup script for YOLO detection system.
Removes all unnecessary files while preserving core functionality.
"""

import os
import shutil
from pathlib import Path
import json

def deep_clean_project():
    """Perform deep cleaning of unnecessary files"""
    
    base_path = Path("d:/akhil")
    removed_items = []
    space_freed = 0
    
    print("üßπ Starting deep cleanup of project structure...")
    print("=" * 60)
    
    # 1. Remove duplicate README files (keep only main README.md)
    print("\n1. Removing duplicate README files...")
    readme_files = [
        "Accident_detection_model/Accident-Detection-Model/README.md",
        "Fight_model/Fight-Violence-detection-yolov8/README.md", 
        "NSFW_Detectio/nsfw_detector_annotator/README.md",
        "Weapon-Detection-YOLO/README.md",
        "fire_detection_model/README (1).md",
        "integrated_yolo_runner/README.md"  # Keep this one as it has specific usage info
    ]
    
    for readme in readme_files:
        readme_path = base_path / readme
        if readme_path.exists() and readme != "integrated_yolo_runner/README.md":
            try:
                size = readme_path.stat().st_size
                readme_path.unlink()
                removed_items.append(f"README: {readme}")
                space_freed += size
                print(f"  ‚úÖ Removed: {readme}")
            except Exception as e:
                print(f"  ‚ùå Could not remove {readme}: {e}")
    
    # 2. Remove dataset documentation files
    print("\n2. Removing dataset documentation...")
    dataset_docs = [
        "Accident_detection_model/Accident-Detection-Model/data/README.dataset.txt",
        "Accident_detection_model/Accident-Detection-Model/data/README.roboflow.txt"
    ]
    
    for doc in dataset_docs:
        doc_path = base_path / doc
        if doc_path.exists():
            try:
                size = doc_path.stat().st_size
                doc_path.unlink()
                removed_items.append(f"Dataset doc: {doc}")
                space_freed += size
                print(f"  ‚úÖ Removed: {doc}")
            except Exception as e:
                print(f"  ‚ùå Could not remove {doc}: {e}")
    
    # 3. Remove all runs/detect directories (test outputs)
    print("\n3. Removing test output directories...")
    runs_dirs = list(base_path.glob("**/runs/detect"))
    for runs_dir in runs_dirs:
        if runs_dir.exists() and runs_dir.is_dir():
            try:
                size = sum(f.stat().st_size for f in runs_dir.rglob('*') if f.is_file())
                shutil.rmtree(runs_dir)
                removed_items.append(f"Test outputs: {runs_dir.relative_to(base_path)}")
                space_freed += size
                print(f"  ‚úÖ Removed: {runs_dir.relative_to(base_path)}")
            except Exception as e:
                print(f"  ‚ùå Could not remove {runs_dir}: {e}")
    
    # 4. Remove duplicate requirements.txt files (keep only main one)
    print("\n4. Consolidating requirements files...")
    requirements_files = [
        "Fight_model/Fight-Violence-detection-yolov8/requirements.txt",
        "Weapon-Detection-YOLO/requirements.txt"
    ]
    
    for req_file in requirements_files:
        req_path = base_path / req_file
        if req_path.exists():
            try:
                size = req_path.stat().st_size
                req_path.unlink()
                removed_items.append(f"Duplicate requirements: {req_file}")
                space_freed += size
                print(f"  ‚úÖ Removed: {req_file}")
            except Exception as e:
                print(f"  ‚ùå Could not remove {req_file}: {e}")
    
    # 5. Remove configuration files from Object-detection-master (unused project)
    print("\n5. Removing unused configuration files...")
    config_files = list(base_path.glob("Object-detection-master/**/*.cfg"))
    for config_file in config_files:
        try:
            size = config_file.stat().st_size
            config_file.unlink()
            removed_items.append(f"Config: {config_file.relative_to(base_path)}")
            space_freed += size
            print(f"  ‚úÖ Removed: {config_file.relative_to(base_path)}")
        except Exception as e:
            print(f"  ‚ùå Could not remove {config_file}: {e}")
    
    # 6. Remove duplicate data.yaml files
    print("\n6. Removing duplicate data configuration...")
    yaml_files = [
        "Accident_detection_model/Accident-Detection-Model/data/data.yaml"  # Keep the main one
    ]
    
    for yaml_file in yaml_files:
        yaml_path = base_path / yaml_file
        if yaml_path.exists():
            try:
                size = yaml_path.stat().st_size
                yaml_path.unlink()
                removed_items.append(f"Duplicate YAML: {yaml_file}")
                space_freed += size
                print(f"  ‚úÖ Removed: {yaml_file}")
            except Exception as e:
                print(f"  ‚ùå Could not remove {yaml_file}: {e}")
    
    # 7. Remove Jupyter notebook checkpoints
    print("\n7. Removing Jupyter checkpoints...")
    checkpoint_dirs = list(base_path.glob("**/.ipynb_checkpoints"))
    for checkpoint_dir in checkpoint_dirs:
        if checkpoint_dir.exists() and checkpoint_dir.is_dir():
            try:
                size = sum(f.stat().st_size for f in checkpoint_dir.rglob('*') if f.is_file())
                shutil.rmtree(checkpoint_dir)
                removed_items.append(f"Jupyter checkpoint: {checkpoint_dir.relative_to(base_path)}")
                space_freed += size
                print(f"  ‚úÖ Removed: {checkpoint_dir.relative_to(base_path)}")
            except Exception as e:
                print(f"  ‚ùå Could not remove {checkpoint_dir}: {e}")
    
    # 8. Remove license and contributing files from individual projects
    print("\n8. Removing individual project metadata...")
    metadata_files = [
        "Weapon-Detection-YOLO/LICENSE",
        "Weapon-Detection-YOLO/CODE_OF_CONDUCT.md", 
        "Weapon-Detection-YOLO/CONTRIBUTING.md"
    ]
    
    for meta_file in metadata_files:
        meta_path = base_path / meta_file
        if meta_path.exists():
            try:
                size = meta_path.stat().st_size
                meta_path.unlink()
                removed_items.append(f"Metadata: {meta_file}")
                space_freed += size
                print(f"  ‚úÖ Removed: {meta_file}")
            except Exception as e:
                print(f"  ‚ùå Could not remove {meta_file}: {e}")
    
    # 9. Remove empty directories
    print("\n9. Removing empty directories...")
    for root, dirs, files in os.walk(base_path, topdown=False):
        for dir_name in dirs:
            dir_path = Path(root) / dir_name
            try:
                if dir_path.exists() and dir_path.is_dir() and not any(dir_path.iterdir()):
                    dir_path.rmdir()
                    removed_items.append(f"Empty directory: {dir_path.relative_to(base_path)}")
                    print(f"  ‚úÖ Removed empty: {dir_path.relative_to(base_path)}")
            except Exception:
                pass  # Directory not empty or permission issue
    
    # 10. Remove duplicate model files (keep only one yolov8n.pt)
    print("\n10. Removing duplicate model files...")
    # Remove the duplicate yolov8n.pt from integrated_yolo_runner (keep the one in fire_detection_model)
    duplicate_model = base_path / "integrated_yolo_runner/yolov8n.pt"
    if duplicate_model.exists():
        try:
            size = duplicate_model.stat().st_size
            duplicate_model.unlink()
            removed_items.append("Duplicate model: integrated_yolo_runner/yolov8n.pt")
            space_freed += size
            print(f"  ‚úÖ Removed duplicate: integrated_yolo_runner/yolov8n.pt")
        except Exception as e:
            print(f"  ‚ùå Could not remove duplicate model: {e}")
    
    space_freed_mb = space_freed / (1024 * 1024)
    
    print("\n" + "=" * 60)
    print("üéâ Deep cleanup completed!")
    print(f"üìä Items removed: {len(removed_items)}")
    print(f"üíæ Space freed: {space_freed_mb:.2f} MB")
    
    # Create cleanup report
    cleanup_report = {
        "timestamp": "2025-09-13T09:12:17+05:30",
        "items_removed": len(removed_items),
        "space_freed_mb": round(space_freed_mb, 2),
        "removed_items": removed_items
    }
    
    with open(base_path / "deep_cleanup_report.json", "w") as f:
        json.dump(cleanup_report, f, indent=2)
    
    print(f"üìù Cleanup report saved to: deep_cleanup_report.json")
    
    return removed_items, space_freed_mb

def update_model_registry():
    """Update the model registry in run.py to reflect cleaned structure"""
    
    base_path = Path("d:/akhil")
    run_py_path = base_path / "integrated_yolo_runner/run.py"
    
    print("\nüîß Updating model registry...")
    
    # Read the current run.py file
    with open(run_py_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Update the MODEL_REGISTRY to use correct paths after cleanup
    old_registry = '''MODEL_REGISTRY = {
    # Accident
    "accident": WORKSPACE / "Accident_detection_model/Accident-Detection-Model/yolov8s.pt",
    # Fight
    "fight_nano": WORKSPACE / "Fight_model/Fight-Violence-detection-yolov8/Yolo_nano_weights.pt",
    "fight_small": WORKSPACE / "Fight_model/Fight-Violence-detection-yolov8/yolo_small_weights.pt",
    # Weapon
    "weapon": WORKSPACE / "Weapon-Detection-YOLO/best (3).pt",
    # Fire (choose small/nano as needed)
    "fire_n": WORKSPACE / "fire_detection_model/yolov8n.pt",
    "fire_s": WORKSPACE / "fire_detection_model/yolov8s (1).pt",
    # NSFW (classification & segmentation)
    "nsfw_cls": WORKSPACE / "NSFW_Detectio/nsfw_detector_annotator/models/classification_model.pt",
    "nsfw_seg": WORKSPACE / "NSFW_Detectio/nsfw_detector_annotator/models/segmentation_model.pt",
    # Generic COCO object detector (Ultralytics will auto-download if absent)
    "objects": Path("yolov8n.pt"),
}'''
    
    new_registry = '''MODEL_REGISTRY = {
    # Accident
    "accident": WORKSPACE / "Accident_detection_model/Accident-Detection-Model/yolov8s.pt",
    # Fight
    "fight_nano": WORKSPACE / "Fight_model/Fight-Violence-detection-yolov8/Yolo_nano_weights.pt",
    "fight_small": WORKSPACE / "Fight_model/Fight-Violence-detection-yolov8/yolo_small_weights.pt",
    # Weapon
    "weapon": WORKSPACE / "Weapon-Detection-YOLO/best (3).pt",
    # Fire (choose small/nano as needed)
    "fire_n": WORKSPACE / "fire_detection_model/yolov8n.pt",
    "fire_s": WORKSPACE / "fire_detection_model/yolov8s (1).pt",
    # NSFW (classification & segmentation)
    "nsfw_cls": WORKSPACE / "NSFW_Detectio/nsfw_detector_annotator/models/classification_model.pt",
    "nsfw_seg": WORKSPACE / "NSFW_Detectio/nsfw_detector_annotator/models/segmentation_model.pt",
    # Generic COCO object detector (will auto-download)
    "objects": Path("yolov8n.pt"),
}'''
    
    # Replace the registry
    updated_content = content.replace(old_registry, new_registry)
    
    # Write back the updated content
    with open(run_py_path, 'w', encoding='utf-8') as f:
        f.write(updated_content)
    
    print("‚úÖ Model registry updated successfully")

if __name__ == "__main__":
    # Perform deep cleanup
    removed_items, space_freed = deep_clean_project()
    
    # Update model registry
    update_model_registry()
    
    print(f"\nüöÄ Project is now optimized and ready for deployment!")
    print(f"üìÅ Total cleanup: {len(removed_items)} items, {space_freed:.2f} MB freed")
